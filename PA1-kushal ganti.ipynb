{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 1\n",
    " * CSCI-5930 ML Spring 2019 \n",
    "* Author: Kushal Ganti "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks for everyone (Tasks 1-15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1: Import all the necessary packages here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy as stats\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt \n",
    "#import matplotlib.pyplot as plt\n",
    "import random \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2: Load the dataset into memory so that you can play with it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101400, 37)\n",
      "     ID  SEX  MARITAL  FAGE  GAINED  VISITS  MAGE  FEDUC  MEDUC  TOTALP  \\\n",
      "0  2001    2        1    33      26      10    34     12      4       2   \n",
      "1  2002    2        2    19      40      10    18     11     12       1   \n",
      "2  2003    2        1    33      16      14    31     16     16       2   \n",
      "3  2004    1        1    25      40      15    28     12     12       3   \n",
      "4  2005    1        2    21      60      13    20     12     14       2   \n",
      "\n",
      "    ...     HYPERCH  HYPERPR  ECLAMP  CERVIX  PINFANT  PRETERM RENAL RHSEN  \\\n",
      "0   ...           0        0       0       0        0        0     0     0   \n",
      "1   ...           0        0       0       0        0        0     0     0   \n",
      "2   ...           0        0       0       0        0        0     0     0   \n",
      "3   ...           0        0       0       0        0        0     0     0   \n",
      "4   ...           0        1       0       0        0        0     0     0   \n",
      "\n",
      "   UTERINE  BWEIGHT  \n",
      "0        0   4.3750  \n",
      "1        0   6.9375  \n",
      "2        0   8.5000  \n",
      "3        0   8.5000  \n",
      "4        0   9.0000  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "df_dataset = pd.read_csv('C:/Users/kusha/Desktop/sem2/ML/programming assignment/new/baby-weights-dataset2.csv')\n",
    "#print (df_dataset)\n",
    "print(df_dataset.shape)\n",
    "print(df_dataset.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 3: Compute mean, stdev, min, max, 25% percentile, median and 75% percentile of the dataset (BWEIGHT variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean= 7.2580658284023665\n",
      "Min= 0.1875\n",
      "Max= 13.0625\n",
      "Stdev=  1.3294541253577947\n",
      "Median= 7.375\n",
      "25%percentile 6.625\n",
      "75%percentile 8.0625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#calculate mean\n",
    "\n",
    "Mean = np.mean(df_dataset['BWEIGHT'])\n",
    "#cal min\n",
    "Min = np.min(df_dataset['BWEIGHT'])\n",
    "#cal max\n",
    "Max = np.max(df_dataset['BWEIGHT'])\n",
    "#cal standard deviation\n",
    "Stdev= np.std(df_dataset['BWEIGHT'])\n",
    "#cal median\n",
    "Median = np.median(df_dataset['BWEIGHT'])\n",
    "#25%\n",
    "b= np.percentile(df_dataset['BWEIGHT'],25)\n",
    "# 75%\n",
    "c= np.percentile(df_dataset['BWEIGHT'],75)\n",
    "\n",
    "print (\"Mean=\" , Mean )\n",
    "print (\"Min=\", Min)\n",
    "print (\"Max=\" ,Max)\n",
    "print (\"Stdev= \" , Stdev)\n",
    "print (\"Median=\", Median)\n",
    "print (\"25%percentile\" , b)\n",
    "print (\"75%percentile\" , c)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 4: Also, draw the histogram plot for the BWEIGHT variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.xlabel('BWEIGHT')\n",
    "plt.ylabel('OUTPUT')\n",
    "plt.title(\"HISTOGRAM\")\n",
    " #plt.ylabel(\"YAXIS\")\n",
    "plt.hist(df_dataset['BWEIGHT'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 5: Present the skewness and kurtosis of the BWEIGHT target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness: -0.936593\n",
      "Kurtosis: 2.868780\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(df_dataset['BWEIGHT']);\n",
    "\n",
    "print(\"Skewness: %f\" % df_dataset['BWEIGHT'].skew())\n",
    "print(\"Kurtosis: %f\" % df_dataset['BWEIGHT'].kurt())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 6: Do variable selection from the pool of 124 variables based on correlation score with the target variable BWEIGHT \n",
    "### Please report all the variables you kept for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "                 ID       SEX   MARITAL      FAGE    GAINED    VISITS  \\\n",
      "ID         1.000000 -0.002444 -0.000799 -0.000815 -0.004517 -0.001223   \n",
      "SEX       -0.002444  1.000000 -0.000217 -0.001383 -0.029824  0.000475   \n",
      "MARITAL   -0.000799 -0.000217  1.000000 -0.326817  0.004582 -0.164554   \n",
      "FAGE      -0.000815 -0.001383 -0.326817  1.000000 -0.055416  0.100619   \n",
      "GAINED    -0.004517 -0.029824  0.004582 -0.055416  1.000000  0.091973   \n",
      "VISITS    -0.001223  0.000475 -0.164554  0.100619  0.091973  1.000000   \n",
      "MAGE       0.002728 -0.004593 -0.400774  0.750074 -0.062252  0.138458   \n",
      "FEDUC      0.002352 -0.000193 -0.358460  0.282474  0.107655  0.209027   \n",
      "MEDUC      0.001940  0.000966 -0.371508  0.272225  0.107535  0.230714   \n",
      "TOTALP     0.003152 -0.006945 -0.056250  0.282043 -0.123318 -0.058236   \n",
      "BDEAD      0.001949 -0.003890 -0.004599  0.040859 -0.015823 -0.000124   \n",
      "TERMS      0.004128 -0.006555 -0.014833  0.126696 -0.012694  0.032781   \n",
      "LOUTCOME  -0.005958  0.004687  0.098247 -0.255937  0.141953  0.050606   \n",
      "WEEKS      0.006103  0.018815 -0.014918 -0.038116  0.098017  0.136121   \n",
      "RACEMOM    0.006846  0.000686  0.006598  0.051216 -0.029612 -0.015863   \n",
      "RACEDAD    0.003994  0.003727  0.030467  0.032006 -0.028377 -0.012669   \n",
      "CIGNUM     0.002639  0.001175  0.121011 -0.037478 -0.011584 -0.056671   \n",
      "DRINKNUM  -0.002534  0.000433  0.011760  0.014737  0.001187 -0.013428   \n",
      "ANEMIA    -0.001148  0.009119  0.039257 -0.022622 -0.004694 -0.039471   \n",
      "CARDIAC    0.002897  0.006264 -0.009541  0.011831 -0.000701  0.005190   \n",
      "ACLUNG    -0.002304  0.002588  0.023449 -0.012613  0.001676 -0.016838   \n",
      "DIABETES  -0.000110  0.000501 -0.021310  0.062800 -0.050173  0.056529   \n",
      "HERPES    -0.001558 -0.004529  0.016336  0.017447  0.013836 -0.005063   \n",
      "HYDRAM    -0.003973  0.001713  0.013904 -0.002528 -0.004185 -0.007633   \n",
      "HEMOGLOB   0.002899  0.001187  0.023385 -0.004338 -0.011292 -0.012718   \n",
      "HYPERCH    0.003026  0.003384 -0.009593  0.054330 -0.031150  0.025262   \n",
      "HYPERPR   -0.003755 -0.006445  0.009583 -0.010430  0.059414  0.016096   \n",
      "ECLAMP    -0.001152 -0.004311  0.005128 -0.002490  0.019534 -0.007458   \n",
      "CERVIX     0.003712  0.000624 -0.005323  0.018673 -0.009036  0.016443   \n",
      "PINFANT    0.000321 -0.000720 -0.023111  0.036807  0.009676 -0.003895   \n",
      "PRETERM    0.009510 -0.002342 -0.002707  0.024458 -0.024123 -0.006673   \n",
      "RENAL      0.003160  0.000076  0.001630 -0.004383 -0.000447 -0.005545   \n",
      "RHSEN     -0.000312  0.003531 -0.003273  0.001546  0.005285 -0.001136   \n",
      "UTERINE   -0.001814 -0.003870  0.001819  0.004551 -0.004833 -0.016686   \n",
      "BWEIGHT    0.003001 -0.093440 -0.107106  0.051447  0.173262  0.129587   \n",
      "HISPMOM_C -0.001207 -0.002240 -0.006636  0.000059  0.005154  0.003667   \n",
      "HISPMOM_M  0.002091  0.000299  0.110567 -0.063633 -0.114515 -0.145693   \n",
      "HISPMOM_N  0.003264 -0.001845 -0.130263  0.059850  0.115288  0.164894   \n",
      "HISPMOM_O  0.000529  0.001856  0.002931 -0.017346  0.005498 -0.002320   \n",
      "HISPMOM_P -0.006624  0.001557  0.010799 -0.023796  0.005974 -0.004698   \n",
      "HISPMOM_S -0.006044  0.002644  0.064432  0.005313 -0.038456 -0.077200   \n",
      "HISPMOM_U -0.002085 -0.001101  0.004308 -0.004644 -0.003465  0.004111   \n",
      "HISPDAD_C  0.000751 -0.001997 -0.008775  0.001923  0.003239 -0.005827   \n",
      "HISPDAD_M -0.001853  0.004327  0.122134 -0.075638 -0.109169 -0.144828   \n",
      "HISPDAD_N  0.002102 -0.005660 -0.141861  0.075754  0.111288  0.163006   \n",
      "HISPDAD_O -0.002622  0.001556  0.004497 -0.008051  0.008107  0.002904   \n",
      "HISPDAD_P  0.003335  0.005018  0.003097 -0.025321  0.005733 -0.003876   \n",
      "HISPDAD_S -0.002250  0.001827  0.069275 -0.005699 -0.037916 -0.072842   \n",
      "HISPDAD_U -0.000468 -0.001907  0.013809 -0.008657 -0.004101  0.003426   \n",
      "\n",
      "               MAGE     FEDUC     MEDUC    TOTALP    ...      HISPMOM_P  \\\n",
      "ID         0.002728  0.002352  0.001940  0.003152    ...      -0.006624   \n",
      "SEX       -0.004593 -0.000193  0.000966 -0.006945    ...       0.001557   \n",
      "MARITAL   -0.400774 -0.358460 -0.371508 -0.056250    ...       0.010799   \n",
      "FAGE       0.750074  0.282474  0.272225  0.282043    ...      -0.023796   \n",
      "GAINED    -0.062252  0.107655  0.107535 -0.123318    ...       0.005974   \n",
      "VISITS     0.138458  0.209027  0.230714 -0.058236    ...      -0.004698   \n",
      "MAGE       1.000000  0.344820  0.373315  0.348340    ...      -0.021705   \n",
      "FEDUC      0.344820  1.000000  0.742290 -0.095594    ...       0.002688   \n",
      "MEDUC      0.373315  0.742290  1.000000 -0.133025    ...       0.001573   \n",
      "TOTALP     0.348340 -0.095594 -0.133025  1.000000    ...       0.002821   \n",
      "BDEAD      0.040497 -0.018623 -0.023191  0.166944    ...      -0.001134   \n",
      "TERMS      0.171695  0.024686  0.030971  0.651354    ...       0.008399   \n",
      "LOUTCOME  -0.303697  0.064898  0.089720 -0.631086    ...       0.002473   \n",
      "WEEKS     -0.053401  0.005810  0.002858 -0.082212    ...      -0.013288   \n",
      "RACEMOM    0.028325  0.091697  0.069408 -0.005291    ...      -0.022461   \n",
      "RACEDAD    0.007115  0.084677  0.058174  0.002045    ...      -0.002127   \n",
      "CIGNUM    -0.077175 -0.109378 -0.121786  0.077844    ...      -0.012536   \n",
      "DRINKNUM   0.013221  0.003343  0.002534  0.018470    ...      -0.002530   \n",
      "ANEMIA    -0.026186 -0.022098 -0.026060  0.018098    ...       0.003926   \n",
      "CARDIAC    0.014139  0.008469  0.013153  0.002735    ...      -0.001340   \n",
      "ACLUNG    -0.017564 -0.006696 -0.005759  0.007163    ...       0.009825   \n",
      "DIABETES   0.082295 -0.014301 -0.006601  0.047224    ...      -0.001054   \n",
      "HERPES     0.015740  0.009405  0.013545  0.012620    ...       0.004146   \n",
      "HYDRAM    -0.006013 -0.013799 -0.008656 -0.012317    ...      -0.001156   \n",
      "HEMOGLOB  -0.008484 -0.004338 -0.003220  0.012015    ...      -0.001387   \n",
      "HYPERCH    0.063762 -0.000837  0.013851  0.026276    ...      -0.005776   \n",
      "HYPERPR   -0.004131 -0.007234  0.007150 -0.035673    ...      -0.001005   \n",
      "ECLAMP    -0.001404 -0.004202 -0.001311 -0.008284    ...      -0.000734   \n",
      "CERVIX     0.021701  0.009924  0.012939  0.036607    ...       0.001089   \n",
      "PINFANT    0.042554  0.005027  0.005202  0.062430    ...      -0.000165   \n",
      "PRETERM    0.024574 -0.005768 -0.007334  0.084700    ...       0.003388   \n",
      "RENAL     -0.006746 -0.004526 -0.002946  0.000847    ...       0.002310   \n",
      "RHSEN      0.001592  0.007526  0.007772 -0.001073    ...       0.001022   \n",
      "UTERINE    0.007406  0.003655  0.005310  0.006205    ...       0.006996   \n",
      "BWEIGHT    0.068473  0.052673  0.055908  0.003201    ...      -0.015643   \n",
      "HISPMOM_C -0.002064  0.010465  0.008711 -0.007601    ...      -0.004048   \n",
      "HISPMOM_M -0.075173 -0.457386 -0.469988  0.069260    ...      -0.033515   \n",
      "HISPMOM_N  0.073027  0.478183  0.499400 -0.069520    ...      -0.215875   \n",
      "HISPMOM_O -0.015863 -0.005095 -0.003747 -0.002013    ...      -0.003457   \n",
      "HISPMOM_P -0.021705  0.002688  0.001573  0.002821    ...       1.000000   \n",
      "HISPMOM_S -0.002036 -0.171362 -0.190611  0.020149    ...      -0.018573   \n",
      "HISPMOM_U -0.004274 -0.005627 -0.008108  0.003776    ...      -0.002853   \n",
      "HISPDAD_C  0.001201  0.011939  0.005367 -0.004391    ...       0.030324   \n",
      "HISPDAD_M -0.084553 -0.472006 -0.472237  0.078472    ...      -0.016885   \n",
      "HISPDAD_N  0.088276  0.504061  0.505782 -0.076028    ...      -0.065695   \n",
      "HISPDAD_O -0.003345  0.003126 -0.000717 -0.002457    ...       0.002933   \n",
      "HISPDAD_P -0.023789 -0.000920 -0.002921 -0.001179    ...       0.234167   \n",
      "HISPDAD_S -0.016995 -0.191019 -0.190494  0.019018    ...       0.036372   \n",
      "HISPDAD_U -0.006737 -0.013953 -0.016194 -0.004243    ...       0.000342   \n",
      "\n",
      "           HISPMOM_S  HISPMOM_U  HISPDAD_C  HISPDAD_M  HISPDAD_N  HISPDAD_O  \\\n",
      "ID         -0.006044  -0.002085   0.000751  -0.001853   0.002102  -0.002622   \n",
      "SEX         0.002644  -0.001101  -0.001997   0.004327  -0.005660   0.001556   \n",
      "MARITAL     0.064432   0.004308  -0.008775   0.122134  -0.141861   0.004497   \n",
      "FAGE        0.005313  -0.004644   0.001923  -0.075638   0.075754  -0.008051   \n",
      "GAINED     -0.038456  -0.003465   0.003239  -0.109169   0.111288   0.008107   \n",
      "VISITS     -0.077200   0.004111  -0.005827  -0.144828   0.163006   0.002904   \n",
      "MAGE       -0.002036  -0.004274   0.001201  -0.084553   0.088276  -0.003345   \n",
      "FEDUC      -0.171362  -0.005627   0.011939  -0.472006   0.504061   0.003126   \n",
      "MEDUC      -0.190611  -0.008108   0.005367  -0.472237   0.505782  -0.000717   \n",
      "TOTALP      0.020149   0.003776  -0.004391   0.078472  -0.076028  -0.002457   \n",
      "BDEAD       0.000984  -0.000887  -0.002939   0.003782  -0.001785   0.002535   \n",
      "TERMS      -0.021404  -0.004157   0.002262  -0.051334   0.055382  -0.004630   \n",
      "LOUTCOME   -0.026703  -0.001149   0.004617  -0.089507   0.088694   0.004109   \n",
      "WEEKS       0.011389  -0.001788   0.001305   0.021316  -0.022400   0.002333   \n",
      "RACEMOM    -0.065926  -0.005928  -0.009029  -0.115806   0.131971  -0.006226   \n",
      "RACEDAD    -0.058119  -0.003277  -0.009401  -0.126881   0.152344  -0.010893   \n",
      "CIGNUM     -0.046010  -0.004708  -0.007435  -0.066016   0.081419  -0.004437   \n",
      "DRINKNUM   -0.003231  -0.000805  -0.001145  -0.008487   0.007851   0.004656   \n",
      "ANEMIA     -0.001058   0.001281   0.006689   0.005165  -0.006148   0.004370   \n",
      "CARDIAC    -0.005593  -0.001969   0.000742  -0.014608   0.016874  -0.002230   \n",
      "ACLUNG     -0.001621  -0.000109  -0.000203  -0.017189   0.015833   0.001843   \n",
      "DIABETES   -0.002696  -0.000077  -0.000194   0.004417  -0.002001  -0.001459   \n",
      "HERPES     -0.010765  -0.003436  -0.002839  -0.023965   0.025366  -0.001321   \n",
      "HYDRAM      0.008400  -0.000979   0.000474   0.003007  -0.006121  -0.004183   \n",
      "HEMOGLOB   -0.003087  -0.001249   0.003791  -0.010061   0.011672  -0.001415   \n",
      "HYPERCH    -0.011526  -0.000749  -0.005065  -0.026098   0.027895   0.000932   \n",
      "HYPERPR    -0.012691  -0.002409  -0.002439  -0.025929   0.025686  -0.001200   \n",
      "ECLAMP     -0.007039  -0.001863   0.008578  -0.006351   0.006027  -0.002110   \n",
      "CERVIX     -0.004314   0.003522   0.001151  -0.013988   0.015068  -0.002091   \n",
      "PINFANT     0.001847  -0.002278  -0.003240   0.008362  -0.007314  -0.002580   \n",
      "PRETERM    -0.003495  -0.002849  -0.001592  -0.004106   0.005462  -0.003226   \n",
      "RENAL      -0.001369   0.005597  -0.002008  -0.003495   0.002500  -0.001599   \n",
      "RHSEN      -0.007823  -0.001856  -0.002640  -0.014648   0.016138   0.012045   \n",
      "UTERINE     0.001845  -0.001771   0.001416   0.001855  -0.002315   0.002933   \n",
      "BWEIGHT     0.002801  -0.002477  -0.003446   0.024415  -0.017442  -0.002750   \n",
      "HISPMOM_C  -0.008386  -0.001288   0.203395  -0.007119  -0.027653   0.005319   \n",
      "HISPMOM_M  -0.069432  -0.010667  -0.008580   0.833124  -0.723227  -0.003806   \n",
      "HISPMOM_N  -0.447219  -0.068706  -0.042600  -0.715911   0.823239  -0.016484   \n",
      "HISPMOM_O  -0.007162  -0.001100  -0.001565   0.009174  -0.026896   0.125681   \n",
      "HISPMOM_P  -0.018573  -0.002853   0.030324  -0.016885  -0.065695   0.002933   \n",
      "HISPMOM_S   1.000000  -0.005911   0.036737   0.014033  -0.350344   0.011681   \n",
      "HISPMOM_U  -0.005911   1.000000  -0.001292   0.006154  -0.027545  -0.001029   \n",
      "HISPDAD_C   0.036737  -0.001292   1.000000  -0.015735  -0.095185  -0.001463   \n",
      "HISPDAD_M   0.014033   0.006154  -0.015735   1.000000  -0.814990  -0.012528   \n",
      "HISPDAD_N  -0.350344  -0.027545  -0.095185  -0.814990   1.000000  -0.075789   \n",
      "HISPDAD_O   0.011681  -0.001029  -0.001463  -0.012528  -0.075789   1.000000   \n",
      "HISPDAD_P   0.028220   0.000697  -0.004020  -0.034421  -0.208228  -0.003201   \n",
      "HISPDAD_S   0.642689   0.002733  -0.008425  -0.072137  -0.436385  -0.006708   \n",
      "HISPDAD_U   0.013668   0.248261  -0.001354  -0.011590  -0.070111  -0.001078   \n",
      "\n",
      "           HISPDAD_P  HISPDAD_S  HISPDAD_U  \n",
      "ID          0.003335  -0.002250  -0.000468  \n",
      "SEX         0.005018   0.001827  -0.001907  \n",
      "MARITAL     0.003097   0.069275   0.013809  \n",
      "FAGE       -0.025321  -0.005699  -0.008657  \n",
      "GAINED      0.005733  -0.037916  -0.004101  \n",
      "VISITS     -0.003876  -0.072842   0.003426  \n",
      "MAGE       -0.023789  -0.016995  -0.006737  \n",
      "FEDUC      -0.000920  -0.191019  -0.013953  \n",
      "MEDUC      -0.002921  -0.190494  -0.016194  \n",
      "TOTALP     -0.001179   0.019018  -0.004243  \n",
      "BDEAD      -0.005486   0.000162  -0.001147  \n",
      "TERMS       0.003104  -0.021834  -0.007216  \n",
      "LOUTCOME    0.000768  -0.025784   0.006768  \n",
      "WEEKS      -0.004415   0.010198  -0.005153  \n",
      "RACEMOM    -0.011054  -0.053635  -0.005650  \n",
      "RACEDAD    -0.024343  -0.067858  -0.003870  \n",
      "CIGNUM     -0.010041  -0.040627  -0.001295  \n",
      "DRINKNUM    0.005663  -0.004248  -0.000844  \n",
      "ANEMIA      0.003165  -0.000634   0.000682  \n",
      "CARDIAC    -0.004496  -0.005631  -0.002063  \n",
      "ACLUNG      0.004076  -0.003673  -0.003369  \n",
      "DIABETES   -0.002510  -0.001077  -0.005839  \n",
      "HERPES      0.001563  -0.008976  -0.000822  \n",
      "HYDRAM     -0.001825   0.008727  -0.001280  \n",
      "HEMOGLOB   -0.003888  -0.004371  -0.001309  \n",
      "HYPERCH    -0.001065  -0.008461  -0.003731  \n",
      "HYPERPR     0.003778  -0.007338  -0.001511  \n",
      "ECLAMP      0.001094  -0.003686   0.003125  \n",
      "CERVIX      0.001210  -0.006059  -0.001934  \n",
      "PINFANT    -0.000030   0.001788  -0.002387  \n",
      "PRETERM     0.002459  -0.003558  -0.002985  \n",
      "RENAL       0.000147  -0.000285   0.011899  \n",
      "RHSEN      -0.000586  -0.007853  -0.001944  \n",
      "UTERINE     0.001734   0.000019  -0.001856  \n",
      "BWEIGHT    -0.010593   0.000731  -0.008848  \n",
      "HISPMOM_C   0.008420   0.016023  -0.001350  \n",
      "HISPMOM_M  -0.014308   0.014768   0.010689  \n",
      "HISPMOM_N  -0.062979  -0.355565  -0.036295  \n",
      "HISPMOM_O  -0.000515   0.015693  -0.001153  \n",
      "HISPMOM_P   0.234167   0.036372   0.000342  \n",
      "HISPMOM_S   0.028220   0.642689   0.013668  \n",
      "HISPMOM_U   0.000697   0.002733   0.248261  \n",
      "HISPDAD_C  -0.004020  -0.008425  -0.001354  \n",
      "HISPDAD_M  -0.034421  -0.072137  -0.011590  \n",
      "HISPDAD_N  -0.208228  -0.436385  -0.070111  \n",
      "HISPDAD_O  -0.003201  -0.006708  -0.001078  \n",
      "HISPDAD_P   1.000000  -0.018431  -0.002961  \n",
      "HISPDAD_S  -0.018431   1.000000  -0.006206  \n",
      "HISPDAD_U  -0.002961  -0.006206   1.000000  \n",
      "\n",
      "[49 rows x 49 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating dimmy variable \n",
    "df_dummydataset=pd.get_dummies(df_dataset)\n",
    "\n",
    "#Correlation data \n",
    "df_corrdata = df_dummydataset.corr()\n",
    "ax = sns.heatmap(df_corrdata)\n",
    "\n",
    "print(len(df_corrdata))\n",
    "print(df_corrdata)\n",
    "c= df_corrdata.iloc[-1,:]\n",
    "#print(a)\n",
    "d= sorted(a, reverse=True)\n",
    "#print(b)\n",
    "df_NewDataSet = df_dataset[['BWEIGHT','WEEKS','GAINED','VISITS','MAGE']]\n",
    "#print(df_NewDataSet)\n",
    "\n",
    "#df_NewDataSet.boxplot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 7: Check for missing data, and apply a \"good\" strategy to tackle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>FAGE</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>FEDUC</th>\n",
       "      <th>MEDUC</th>\n",
       "      <th>TOTALP</th>\n",
       "      <th>...</th>\n",
       "      <th>HYPERCH</th>\n",
       "      <th>HYPERPR</th>\n",
       "      <th>ECLAMP</th>\n",
       "      <th>CERVIX</th>\n",
       "      <th>PINFANT</th>\n",
       "      <th>PRETERM</th>\n",
       "      <th>RENAL</th>\n",
       "      <th>RHSEN</th>\n",
       "      <th>UTERINE</th>\n",
       "      <th>BWEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101370</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101371</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101372</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101373</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101374</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101375</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101376</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101377</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101378</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101379</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101380</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101381</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101382</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101383</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101384</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101385</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101386</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101387</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101388</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101389</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101390</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101391</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101392</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101393</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101394</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101395</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101396</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101397</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101398</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101399</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101400 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID    SEX  MARITAL   FAGE  GAINED  VISITS   MAGE  FEDUC  MEDUC  \\\n",
       "0       False  False    False  False   False   False  False  False  False   \n",
       "1       False  False    False  False   False   False  False  False  False   \n",
       "2       False  False    False  False   False   False  False  False  False   \n",
       "3       False  False    False  False   False   False  False  False  False   \n",
       "4       False  False    False  False   False   False  False  False  False   \n",
       "5       False  False    False  False   False   False  False  False  False   \n",
       "6       False  False    False  False   False   False  False  False  False   \n",
       "7       False  False    False  False   False   False  False  False  False   \n",
       "8       False  False    False  False   False   False  False  False  False   \n",
       "9       False  False    False  False   False   False  False  False  False   \n",
       "10      False  False    False  False   False   False  False  False  False   \n",
       "11      False  False    False  False   False   False  False  False  False   \n",
       "12      False  False    False  False   False   False  False  False  False   \n",
       "13      False  False    False  False   False   False  False  False  False   \n",
       "14      False  False    False  False   False   False  False  False  False   \n",
       "15      False  False    False  False   False   False  False  False  False   \n",
       "16      False  False    False  False   False   False  False  False  False   \n",
       "17      False  False    False  False   False   False  False  False  False   \n",
       "18      False  False    False  False   False   False  False  False  False   \n",
       "19      False  False    False  False   False   False  False  False  False   \n",
       "20      False  False    False  False   False   False  False  False  False   \n",
       "21      False  False    False  False   False   False  False  False  False   \n",
       "22      False  False    False  False   False   False  False  False  False   \n",
       "23      False  False    False  False   False   False  False  False  False   \n",
       "24      False  False    False  False   False   False  False  False  False   \n",
       "25      False  False    False  False   False   False  False  False  False   \n",
       "26      False  False    False  False   False   False  False  False  False   \n",
       "27      False  False    False  False   False   False  False  False  False   \n",
       "28      False  False    False  False   False   False  False  False  False   \n",
       "29      False  False    False  False   False   False  False  False  False   \n",
       "...       ...    ...      ...    ...     ...     ...    ...    ...    ...   \n",
       "101370  False  False    False  False   False   False  False  False  False   \n",
       "101371  False  False    False  False   False   False  False  False  False   \n",
       "101372  False  False    False  False   False   False  False  False  False   \n",
       "101373  False  False    False  False   False   False  False  False  False   \n",
       "101374  False  False    False  False   False   False  False  False  False   \n",
       "101375  False  False    False  False   False   False  False  False  False   \n",
       "101376  False  False    False  False   False   False  False  False  False   \n",
       "101377  False  False    False  False   False   False  False  False  False   \n",
       "101378  False  False    False  False   False   False  False  False  False   \n",
       "101379  False  False    False  False   False   False  False  False  False   \n",
       "101380  False  False    False  False   False   False  False  False  False   \n",
       "101381  False  False    False  False   False   False  False  False  False   \n",
       "101382  False  False    False  False   False   False  False  False  False   \n",
       "101383  False  False    False  False   False   False  False  False  False   \n",
       "101384  False  False    False  False   False   False  False  False  False   \n",
       "101385  False  False    False  False   False   False  False  False  False   \n",
       "101386  False  False    False  False   False   False  False  False  False   \n",
       "101387  False  False    False  False   False   False  False  False  False   \n",
       "101388  False  False    False  False   False   False  False  False  False   \n",
       "101389  False  False    False  False   False   False  False  False  False   \n",
       "101390  False  False    False  False   False   False  False  False  False   \n",
       "101391  False  False    False  False   False   False  False  False  False   \n",
       "101392  False  False    False  False   False   False  False  False  False   \n",
       "101393  False  False    False  False   False   False  False  False  False   \n",
       "101394  False  False    False  False   False   False  False  False  False   \n",
       "101395  False  False    False  False   False   False  False  False  False   \n",
       "101396  False  False    False  False   False   False  False  False  False   \n",
       "101397  False  False    False  False   False   False  False  False  False   \n",
       "101398  False  False    False  False   False   False  False  False  False   \n",
       "101399  False  False    False  False   False   False  False  False  False   \n",
       "\n",
       "        TOTALP   ...     HYPERCH  HYPERPR  ECLAMP  CERVIX  PINFANT  PRETERM  \\\n",
       "0        False   ...       False    False   False   False    False    False   \n",
       "1        False   ...       False    False   False   False    False    False   \n",
       "2        False   ...       False    False   False   False    False    False   \n",
       "3        False   ...       False    False   False   False    False    False   \n",
       "4        False   ...       False    False   False   False    False    False   \n",
       "5        False   ...       False    False   False   False    False    False   \n",
       "6        False   ...       False    False   False   False    False    False   \n",
       "7        False   ...       False    False   False   False    False    False   \n",
       "8        False   ...       False    False   False   False    False    False   \n",
       "9        False   ...       False    False   False   False    False    False   \n",
       "10       False   ...       False    False   False   False    False    False   \n",
       "11       False   ...       False    False   False   False    False    False   \n",
       "12       False   ...       False    False   False   False    False    False   \n",
       "13       False   ...       False    False   False   False    False    False   \n",
       "14       False   ...       False    False   False   False    False    False   \n",
       "15       False   ...       False    False   False   False    False    False   \n",
       "16       False   ...       False    False   False   False    False    False   \n",
       "17       False   ...       False    False   False   False    False    False   \n",
       "18       False   ...       False    False   False   False    False    False   \n",
       "19       False   ...       False    False   False   False    False    False   \n",
       "20       False   ...       False    False   False   False    False    False   \n",
       "21       False   ...       False    False   False   False    False    False   \n",
       "22       False   ...       False    False   False   False    False    False   \n",
       "23       False   ...       False    False   False   False    False    False   \n",
       "24       False   ...       False    False   False   False    False    False   \n",
       "25       False   ...       False    False   False   False    False    False   \n",
       "26       False   ...       False    False   False   False    False    False   \n",
       "27       False   ...       False    False   False   False    False    False   \n",
       "28       False   ...       False    False   False   False    False    False   \n",
       "29       False   ...       False    False   False   False    False    False   \n",
       "...        ...   ...         ...      ...     ...     ...      ...      ...   \n",
       "101370   False   ...       False    False   False   False    False    False   \n",
       "101371   False   ...       False    False   False   False    False    False   \n",
       "101372   False   ...       False    False   False   False    False    False   \n",
       "101373   False   ...       False    False   False   False    False    False   \n",
       "101374   False   ...       False    False   False   False    False    False   \n",
       "101375   False   ...       False    False   False   False    False    False   \n",
       "101376   False   ...       False    False   False   False    False    False   \n",
       "101377   False   ...       False    False   False   False    False    False   \n",
       "101378   False   ...       False    False   False   False    False    False   \n",
       "101379   False   ...       False    False   False   False    False    False   \n",
       "101380   False   ...       False    False   False   False    False    False   \n",
       "101381   False   ...       False    False   False   False    False    False   \n",
       "101382   False   ...       False    False   False   False    False    False   \n",
       "101383   False   ...       False    False   False   False    False    False   \n",
       "101384   False   ...       False    False   False   False    False    False   \n",
       "101385   False   ...       False    False   False   False    False    False   \n",
       "101386   False   ...       False    False   False   False    False    False   \n",
       "101387   False   ...       False    False   False   False    False    False   \n",
       "101388   False   ...       False    False   False   False    False    False   \n",
       "101389   False   ...       False    False   False   False    False    False   \n",
       "101390   False   ...       False    False   False   False    False    False   \n",
       "101391   False   ...       False    False   False   False    False    False   \n",
       "101392   False   ...       False    False   False   False    False    False   \n",
       "101393   False   ...       False    False   False   False    False    False   \n",
       "101394   False   ...       False    False   False   False    False    False   \n",
       "101395   False   ...       False    False   False   False    False    False   \n",
       "101396   False   ...       False    False   False   False    False    False   \n",
       "101397   False   ...       False    False   False   False    False    False   \n",
       "101398   False   ...       False    False   False   False    False    False   \n",
       "101399   False   ...       False    False   False   False    False    False   \n",
       "\n",
       "        RENAL  RHSEN  UTERINE  BWEIGHT  \n",
       "0       False  False    False    False  \n",
       "1       False  False    False    False  \n",
       "2       False  False    False    False  \n",
       "3       False  False    False    False  \n",
       "4       False  False    False    False  \n",
       "5       False  False    False    False  \n",
       "6       False  False    False    False  \n",
       "7       False  False    False    False  \n",
       "8       False  False    False    False  \n",
       "9       False  False    False    False  \n",
       "10      False  False    False    False  \n",
       "11      False  False    False    False  \n",
       "12      False  False    False    False  \n",
       "13      False  False    False    False  \n",
       "14      False  False    False    False  \n",
       "15      False  False    False    False  \n",
       "16      False  False    False    False  \n",
       "17      False  False    False    False  \n",
       "18      False  False    False    False  \n",
       "19      False  False    False    False  \n",
       "20      False  False    False    False  \n",
       "21      False  False    False    False  \n",
       "22      False  False    False    False  \n",
       "23      False  False    False    False  \n",
       "24      False  False    False    False  \n",
       "25      False  False    False    False  \n",
       "26      False  False    False    False  \n",
       "27      False  False    False    False  \n",
       "28      False  False    False    False  \n",
       "29      False  False    False    False  \n",
       "...       ...    ...      ...      ...  \n",
       "101370  False  False    False    False  \n",
       "101371  False  False    False    False  \n",
       "101372  False  False    False    False  \n",
       "101373  False  False    False    False  \n",
       "101374  False  False    False    False  \n",
       "101375  False  False    False    False  \n",
       "101376  False  False    False    False  \n",
       "101377  False  False    False    False  \n",
       "101378  False  False    False    False  \n",
       "101379  False  False    False    False  \n",
       "101380  False  False    False    False  \n",
       "101381  False  False    False    False  \n",
       "101382  False  False    False    False  \n",
       "101383  False  False    False    False  \n",
       "101384  False  False    False    False  \n",
       "101385  False  False    False    False  \n",
       "101386  False  False    False    False  \n",
       "101387  False  False    False    False  \n",
       "101388  False  False    False    False  \n",
       "101389  False  False    False    False  \n",
       "101390  False  False    False    False  \n",
       "101391  False  False    False    False  \n",
       "101392  False  False    False    False  \n",
       "101393  False  False    False    False  \n",
       "101394  False  False    False    False  \n",
       "101395  False  False    False    False  \n",
       "101396  False  False    False    False  \n",
       "101397  False  False    False    False  \n",
       "101398  False  False    False    False  \n",
       "101399  False  False    False    False  \n",
       "\n",
       "[101400 rows x 37 columns]"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to find null data set\n",
    "df_dataset.isnull().sum()\n",
    "df_dataset.isnull()\n",
    "\n",
    "\n",
    "# there is no empty/missing data and hence we get value 0 for isnull().sum() and false for isnull() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 8: Tackle the dummy categorical variables by introducing dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done as part of task 6\n",
    "#df_dummydataset=pd.get_dummies(df_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 9.1: Randomly split the dataset into training, Tr (80%) and testing, Te (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101400\n",
      "81120\n",
      "20280\n",
      "       BWEIGHT  WEEKS  GAINED  VISITS  MAGE\n",
      "53750   7.3125     39      15       9    37\n",
      "49819   6.2500     38      28      10    25\n",
      "41158   6.6250     38      60      11    24\n",
      "45378   7.8750     40      47      13    34\n",
      "2100    7.1250     39      45      12    27\n",
      "41882   6.2500     41       0      16    27\n",
      "34675   7.6875     40      35      12    19\n",
      "87163   7.6875     41      31      13    31\n",
      "78615   7.2500     40      44      12    21\n",
      "89927   6.8125     39      21      12    26\n",
      "73162   6.9375     36      31      11    27\n",
      "12369   9.5000     41      34       8    28\n",
      "53405   6.1875     38      20      13    20\n",
      "91544   6.4375     39      26      16    32\n",
      "98804   6.8750     40       0      12    30\n",
      "17723   7.6875     37      20       3    36\n",
      "33336   9.3750     39      50      11    20\n",
      "21679   6.3750     30      53      15    21\n",
      "13691   6.6250     36      25       9    34\n",
      "71640   7.8125     42      22      15    35\n",
      "19090   6.5000     41      31      13    31\n",
      "47036   6.5000     38      27      10    35\n",
      "12200   8.1875     41      20      15    33\n",
      "41913   6.7500     38      20      14    26\n",
      "50790   2.6875     31      30      12    25\n",
      "47258   7.5000     39       7      12    25\n",
      "34853   6.4375     38      23      12    26\n",
      "28018   9.2500     41      44      14    29\n",
      "72261   7.4375     38      22      12    35\n",
      "7734    7.1250     39      23      13    40\n",
      "...        ...    ...     ...     ...   ...\n",
      "55132   7.1875     38      18      18    31\n",
      "49808   7.8125     40      55      15    26\n",
      "36829   7.0000     39      39      11    24\n",
      "29266   6.9375     37      40       9    29\n",
      "37943   7.5000     41      36      13    22\n",
      "26908   8.5000     39      25      13    35\n",
      "83282   9.1875     38      22       7    33\n",
      "70842   8.6875     40      45      15    29\n",
      "7032    4.3750     31      28      16    23\n",
      "98189   8.1250     39      40      10    18\n",
      "83180   7.5000     42      25      11    23\n",
      "467     9.5000     39      32      18    31\n",
      "55124   5.8750     37      15      12    24\n",
      "51922   6.4375     37      10      12    31\n",
      "70961   7.6250     40      16      14    34\n",
      "90442  10.1250     38      27      12    35\n",
      "45113   7.9375     39      30      12    27\n",
      "77633   8.4375     39      50      12    24\n",
      "66921  10.4375     40      35      12    26\n",
      "35083   7.4375     39      22      18    31\n",
      "81669   6.8125     38      12       8    23\n",
      "74379   6.3750     34      50      10    31\n",
      "58294   8.8125     40      31      12    16\n",
      "84105   8.8750     40      30      14    37\n",
      "33118   7.4375     36      10      11    34\n",
      "31806   7.8750     38      23       5    22\n",
      "80247   3.4375     32      30      39    42\n",
      "51892   8.7500     40      25      14    35\n",
      "55774   7.4375     40      50      20    34\n",
      "26236   6.8750     38       6       7    25\n",
      "\n",
      "[81120 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(df_NewDataSet))\n",
    "#print(df_NewDataSet)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#print(data)\n",
    "df_split =df_NewDataSet\n",
    "#train_test_split will randomly split the data \n",
    "test , train =train_test_split(df_split,test_size=0.8) \n",
    "print(len(train))\n",
    "print(len(test))\n",
    "print(train)\n",
    "test\n",
    "\n",
    "x=train[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y=train[['BWEIGHT']]\n",
    "x_test=test[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y_test=test[['BWEIGHT']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WEEKS</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>x0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105513</td>\n",
       "      <td>-1.123651</td>\n",
       "      <td>-0.924555</td>\n",
       "      <td>1.555990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.294078</td>\n",
       "      <td>-0.167737</td>\n",
       "      <td>-0.656109</td>\n",
       "      <td>-0.459465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.294078</td>\n",
       "      <td>2.185280</td>\n",
       "      <td>-0.387662</td>\n",
       "      <td>-0.627420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.505105</td>\n",
       "      <td>1.229367</td>\n",
       "      <td>0.149231</td>\n",
       "      <td>1.052126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.105513</td>\n",
       "      <td>1.082303</td>\n",
       "      <td>-0.119216</td>\n",
       "      <td>-0.123556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WEEKS    GAINED    VISITS      MAGE  x0\n",
       "0  0.105513 -1.123651 -0.924555  1.555990   1\n",
       "1 -0.294078 -0.167737 -0.656109 -0.459465   1\n",
       "2 -0.294078  2.185280 -0.387662 -0.627420   1\n",
       "3  0.505105  1.229367  0.149231  1.052126   1\n",
       "4  0.105513  1.082303 -0.119216 -0.123556   1"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#standard scalar will normalise the data set \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "#scaled_test = scaler1.fit_transform(x_test)\n",
    "#print(scaled_test)\n",
    "scaled_train_x = pd.DataFrame(scaler.fit_transform(x) , columns=x.columns )\n",
    "scaled_train_x.head()\n",
    "#other = '1'\n",
    "#scaled_train_x1 = pd.DataFrame.append( other,ignore_index=False, verify_integrity=False, sort=None)\n",
    "# adding the bias x0\n",
    "scaled_train_x['x0'] =1\n",
    "scaled_train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 9.3: Apply the training data statistics to normalize the testing data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WEEKS</th>\n",
       "      <th>GAINED</th>\n",
       "      <th>VISITS</th>\n",
       "      <th>MAGE</th>\n",
       "      <th>x0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.503336</td>\n",
       "      <td>-0.313679</td>\n",
       "      <td>-0.643306</td>\n",
       "      <td>-0.626215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.291870</td>\n",
       "      <td>-1.702746</td>\n",
       "      <td>0.692277</td>\n",
       "      <td>-0.291247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.689473</td>\n",
       "      <td>1.075387</td>\n",
       "      <td>2.027860</td>\n",
       "      <td>2.723464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.503336</td>\n",
       "      <td>-0.021244</td>\n",
       "      <td>1.493627</td>\n",
       "      <td>-1.463635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.665503</td>\n",
       "      <td>-0.386788</td>\n",
       "      <td>-0.109073</td>\n",
       "      <td>0.546173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WEEKS    GAINED    VISITS      MAGE  x0\n",
       "0  0.503336 -0.313679 -0.643306 -0.626215   1\n",
       "1 -0.291870 -1.702746  0.692277 -0.291247   1\n",
       "2 -0.689473  1.075387  2.027860  2.723464   1\n",
       "3  0.503336 -0.021244  1.493627 -1.463635   1\n",
       "4 -4.665503 -0.386788 -0.109073  0.546173   1"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similar to training data set we apply the same to test data set\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler1 = StandardScaler()\n",
    "#scaled_test = scaler1.fit_transform(x_test)\n",
    "\n",
    "#print(scaled_test)\n",
    "scaled_test_x = pd.DataFrame(scaler1.fit_transform(x_test) , columns=x_test.columns )\n",
    "scaled_test_x['x0'] =1\n",
    "scaled_test_x.head()\n",
    "# cols=scaled_test.index\n",
    "# print(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 10: Find the linear regression function describing the training dataset using a technique you recently learned in class.  CLOSED-FORM vs. Gradient Descent (batch or stochastic or mini-batch).\n",
    "###          PLEASE DO NOT CALL ANY LIBRARY FUNCTION THAT MIGHT DO THE TASK FOR YOU. If you do, you are most likely get a ZERO for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "               WEEKS        GAINED        VISITS          MAGE            x0\n",
      "WEEKS   8.112000e+04  7.943727e+03  1.093032e+04 -4.301308e+03 -3.764100e-11\n",
      "GAINED  7.943727e+03  8.112000e+04  7.420702e+03 -4.983363e+03  2.476463e-12\n",
      "VISITS  1.093032e+04  7.420702e+03  8.112000e+04  1.097761e+04  1.083400e-11\n",
      "MAGE   -4.301308e+03 -4.983363e+03  1.097761e+04  8.112000e+04  3.934630e-12\n",
      "x0     -3.704370e-11  3.562928e-12  1.040235e-11  3.794298e-12  8.112000e+04\n"
     ]
    }
   ],
   "source": [
    "print('hello')\n",
    "\n",
    "# cal (X.T .X)\n",
    "M = scaled_train_x.T.dot(scaled_train_x)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.27068116e-05, -1.03400954e-06, -1.73185655e-06,\n",
       "         8.44609292e-07,  6.32141985e-21],\n",
       "       [-1.03400954e-06,  1.25855525e-05, -1.12987661e-06,\n",
       "         8.71229325e-07,  7.23677652e-21],\n",
       "       [-1.73185655e-06, -1.12987661e-06,  1.29226016e-05,\n",
       "        -1.90999875e-06, -1.04088165e-20],\n",
       "       [ 8.44609292e-07,  8.71229325e-07, -1.90999875e-06,\n",
       "         1.26841937e-05, -2.89913158e-21],\n",
       "       [ 6.03059797e-21, -9.20824601e-22, -2.30901099e-21,\n",
       "        -9.34653013e-25,  1.23274162e-05]])"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cal inverse of (x.T)X\n",
    "Minv = np.linalg.pinv(M)\n",
    "Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the shape of the matrix\n",
    "Minv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.27068116e-05, -1.03400954e-06, -1.73185655e-06,\n",
       "         8.44609292e-07,  6.32141985e-21],\n",
       "       [-1.03400954e-06,  1.25855525e-05, -1.12987661e-06,\n",
       "         8.71229325e-07,  7.23677652e-21],\n",
       "       [-1.73185655e-06, -1.12987661e-06,  1.29226016e-05,\n",
       "        -1.90999875e-06, -1.04088165e-20],\n",
       "       [ 8.44609292e-07,  8.71229325e-07, -1.90999875e-06,\n",
       "         1.26841937e-05, -2.89913158e-21],\n",
       "       [ 6.03059797e-21, -9.20824601e-22, -2.30901099e-21,\n",
       "        -9.34653013e-25,  1.23274162e-05]])"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the value\n",
    "Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.73447719]\n",
      " [0.16264285]\n",
      " [0.03386184]\n",
      " [0.1342808 ]\n",
      " [7.25735716]]\n"
     ]
    }
   ],
   "source": [
    "#Calculatimg our W value using linear reg formula\n",
    "w =Minv.dot(scaled_train_x.T).dot(y)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11: Predict BWEIGHT target variable for each of the testing dataset using the regression line you learned in Task 10, and report RMSE(testing) (Root Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ypred is               0\n",
      "0      7.470156\n",
      "1      6.750379\n",
      "2      7.360235\n",
      "3      7.477630\n",
      "4      3.837391\n",
      "5      7.964129\n",
      "6      6.235033\n",
      "7      6.681612\n",
      "8      7.102120\n",
      "9      7.489538\n",
      "10     7.642310\n",
      "11     7.739830\n",
      "12     8.297977\n",
      "13     7.192692\n",
      "14     7.301758\n",
      "15     7.171219\n",
      "16     7.241196\n",
      "17     6.596385\n",
      "18     7.475380\n",
      "19     7.502200\n",
      "20     8.078903\n",
      "21     6.948377\n",
      "22     7.171482\n",
      "23     7.489035\n",
      "24     7.582150\n",
      "25     7.428343\n",
      "26     7.110194\n",
      "27     7.309437\n",
      "28     7.557077\n",
      "29     8.146554\n",
      "...         ...\n",
      "20250  7.079512\n",
      "20251  7.190531\n",
      "20252  7.992566\n",
      "20253  6.717114\n",
      "20254  6.607346\n",
      "20255  7.611348\n",
      "20256  7.840308\n",
      "20257  7.552871\n",
      "20258  7.155899\n",
      "20259  5.900476\n",
      "20260  6.974576\n",
      "20261  7.692204\n",
      "20262  8.044669\n",
      "20263  7.085659\n",
      "20264  6.696756\n",
      "20265  6.212922\n",
      "20266  8.524156\n",
      "20267  7.299100\n",
      "20268  8.018165\n",
      "20269  6.725038\n",
      "20270  7.162099\n",
      "20271  7.765278\n",
      "20272  6.873679\n",
      "20273  6.834729\n",
      "20274  7.276429\n",
      "20275  7.213027\n",
      "20276  7.377158\n",
      "20277  7.974412\n",
      "20278  6.574496\n",
      "20279  7.091333\n",
      "\n",
      "[20280 rows x 1 columns]\n",
      "MSE is  1.1548060597278478\n",
      "RMSE is  1.0746190300417389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x275ef0f6400>"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADW9JREFUeJzt3XFonPd9x/HP9yTXauR080hzVFZXezCKQElpOczWGkeapjHS4hQyRpS4NEMg/MeytAxmDzHC/hAzYYz1XzN5ykhyK8sa0qSQKlg+hmELlTIvcXLrVjdNelFapThreyGXWNK3f1gzVmL7rOe503P3fd4vCCc9eu6eb+D89uOfnrszdxcAoPsVsh4AANAaBB0AgiDoABAEQQeAIAg6AARB0AEgCIIOAEEQdAAIgqADQBC9zXYws5OSviRpxd2HN7b9hqRvStor6UeS/tjd3272WLfccovv3bs3xbhAe7zzzjvq7+/PegzgqpaWln7m7h9vtp81e+m/mR2UVJf0T1cE/WFJF9z9uJkdk7Tb3Y82O1ipVPLFxcUb+h8AtlOlUtHIyEjWYwBXZWZL7l5qtl/TJRd3/zdJFz6w+S5Jj2x8/YikL295QgBASyVdQy+6+5uStHF7a+tGAgAk0XQNPS0zm5I0JUnFYlGVSqXdhwS2rF6v89xE10sa9J+a2Sfc/U0z+4SklWvt6O4nJJ2QLq2hs06JTsQaOiJIuuTybUlf3fj6q5Keas04AICkmgbdzMqS/l3Sp82sZmaTko5LGjez/5U0vvE90HXK5bKGh4c1Njam4eFhlcvlrEcCEmu65OLuE9f40ViLZwG2Vblc1vT0tGZnZ7W2tqaenh5NTk5KkiYmrvW0BzoXrxRFbs3MzGh2dlajo6Pq7e3V6OioZmdnNTMzk/VoQCIEHblVrVZ14MCBTdsOHDigarWa0URAOgQduTU0NKQzZ85s2nbmzBkNDQ1lNBGQTtuvQwc61fT0tO688041Go3L2/r6+nTy5MkMpwKS4wwduTU3N6dGo6FC4dIfg0KhoEajobm5uWwHAxIi6Mit+fl5mZnW19clSevr6zIzzc/PZzwZkAxBR6598N1Gm737KNDJCDoABEHQASAIgg4AQRB0AAiCoANAEAQdAIIg6AAQBEEHgCAIOgAEQdABIAiCDgBBEHQACIKgA0AQBB0AgiDoABAEH0GHkMxsW+7P+6ejkxB0hHQjob1etAk1uhFLLsit/v7+LW0HOh1BR27V6/UPxbu/v1/1ej2jiYB0CDpyrV6vy931qaPPyN2JOboaQQeAIAg6AARB0AEgCIIOAEEQdAAIgqADQBAEHQCCIOgAEARBB4AgUgXdzL5uZi+b2TkzK5tZX6sGAwBsTeKgm9keSX8mqeTuw5J6JN3TqsEAAFuTdsmlV9JHzaxX0k2SltOPBABIIvH7obv7G2b2t5Jel/SupHl3n//gfmY2JWlKkorFoiqVStJDAm3FcxPdLnHQzWy3pLsk7ZP0f5L+xcwOu/ujV+7n7icknZCkUqnkIyMjyacF2uXZ74jnJrpdmiWX35f0qru/5e4XJX1L0udbMxYAYKvSBP11Sb9jZjfZpc/yGpNUbc1YAICtShx0d39e0hOSXpD00sZjnWjRXACALUr1IdHu/pCkh1o0CwAgBV4pCgBBpDpDB7bDZ/56Xj9/92Lbj7P32Hfa+vi/9tEd+q+H/qCtx0C+EXR0vJ+/e1E/Ov7Fth6jUqm0/bLFdv+FAbDkAgBBEHQACIKgA0AQBB0AgiDoABAEQQeAILhsER3v5qFjuu2RY+0/0CPtffibhySpvZdfIt8IOjreL6vHuQ4duAEsuQBAEAQdAIIg6AAQBEEHgCAIOgAEQdABIAiCDgBBcB06usK2XMP9bPs/4AJoJ4KOjtfuFxVJl/7C2I7jAO3EkgsABEHQASAIgg4AQRB0AAiCoANAEAQdAIIg6AAQBEEHgCAIOgAEQdABIAiCDgBBEHQACIKgA0AQBB0AgiDoABAEQQeAIFIF3cx+3cyeMLP/NrOqmf1uqwYDAGxN2k8s+oakZ939j8zsI5JuasFMAIAEEgfdzD4m6aCk+yXJ3d+X9H5rxgIAbFWaM/TfkvSWpH80s89IWpL0oLu/c+VOZjYlaUqSisWiKpVKikMCrXXq1Ck9+uijeu2117Xvm7+pw4cPa2xsLOuxgETM3ZPd0awk6T8kfcHdnzezb0j6hbv/1bXuUyqVfHFxMdmkQIuVy2Xde++9H9r++OOPa2JiIoOJgKszsyV3LzXbL80vRWuSau7+/Mb3T0j6XIrHA7bV1WJ+ve1Ap0u85OLuPzGzH5vZp939+5LGJL3SutGA5MxsW+6f9F+4QDukvcrlAUmPbVzh8kNJf5J+JCC9Gwnt9aJNqNGNUgXd3c9KarquAwBoP14pCgBBEHQACIKgA0AQBB0AgiDoABAEQQeAIAg6AARB0AEgCIIOAEEQdAAIgqADQBAEHQCCIOgAEARBB4AgCDoABEHQASAIgg4AQRB0AAiCoANAEAQdAIIg6AAQBEEHgCAIOgAEQdABIAiCDgBBEHQACIKgA0AQBB0AgiDoABAEQQeAIAg6AARB0AEgCIIOAEEQdAAIgqADQBCpg25mPWb2n2b2TCsGAgAk04oz9AclVVvwOACAFFIF3cwGJX1R0j+0ZhwAQFJpz9D/XtJfSFpvwSwAgBR6k97RzL4kacXdl8xs5Dr7TUmakqRisahKpZL0kMC24XmKbmTunuyOZn8j6SuSViX1SfqYpG+5++Fr3adUKvni4mKi4wGtZmbX/FnSPxdAO5jZkruXmu2XeMnF3f/S3Qfdfa+keyQtXC/mAID24jp0AAgi8Rr6ldy9IqnSiscCACTDGToABEHQASAIgg4AQRB0AAiCoANAEAQdAIIg6AAQBEEHgCAIOgAEQdABIAiCDgBBEHQACIKgA0AQBB0AgiDoABAEQQeAIAg6AARB0AEgCIIOAEEQdAAIgqADQBAEHQCCIOgAEARBB4AgCDpyr1AobLoFuhXPYOTe+vr6plugWxF0AAiCoANAEAQdAIIg6Mg9fimKKHgGI/f4pSiiIOgAEARBB4AgCDoABEHQkXs9PT2bboFuRdCRe1zlgigSP4PN7JNmdtrMqmb2spk92MrBgO1y8eLFTbdAt+pNcd9VSX/u7i+Y2c2SlszsOXd/pUWzAdvCzOTul2+BbpX4DN3d33T3Fza+/qWkqqQ9rRoM2C5mtukW6FYtWTQ0s72SPivp+VY8HrBd9u/frx07dkiSduzYof3792c8EZBcmiUXSZKZ7ZL0r5K+5u6/uMrPpyRNSVKxWFSlUkl7SKBlzp49q+PHj2vfvn169dVXdezYMUnieYquZGnWDM1sh6RnJH3X3f+u2f6lUskXFxcTHw9opb6+Pr333nsf2r5z5041Go0MJgKuzsyW3L3UbL80V7mYpFlJ1RuJOdBp7rjjji1tBzpdmjX0L0j6iqTfM7OzG//d2aK5gLZbWFhQb+/mVcfe3l4tLCxkNBGQTuI1dHc/I4nLAtC1VldXZWYqFotaWVnRrbfeqpWVFS5dRNfipXHItUKhoAsXLsjddeHCBV4tiq7Gsxe5tra2pp07d0q69MvQtbW1jCcCkiPoyL16vb7pFuhWBB25t2vXLpmZdu3alfUoQCoEHblWKBRUr9fl7qrX66yho6vx7EWura+va/fu3SoUCtq9ezefK4qulvql/0C3e/vttzfdAt2KM3TkXl9f36ZboFsRdORaX1/f5fdtaTQaRB1djaAj1xqNhg4dOqQnn3xShw4d4k250NUIOnJtYGBA58+f1913363z589rYGAg65GAxAg6cm15eVkHDx7UU089pYMHD2p5eTnrkYDEUr0f+lbxfujoJIVCQXv27NEbb7xx+TNF//97Ll9EJ2n7+6ED3W58fFy1Wk1HjhzR008/rSNHjqhWq2l8fDzr0YBEOENHrt1+++166aWXLn9/22236cUXX8xwIuDDOEMHmiiXy6rX61pYWNBzzz2nhYUF1et1lcvlrEcDEiHoyK2ZmRnNzs5qdHRUvb29Gh0d1ezsrGZmZrIeDUiEoCO3qtWqarWahoeHNTY2puHhYdVqNVWr1axHAxLhvVyQWwMDAzp69Kgee+wxra2tqaenR/fddx/XoqNrcYaOXPvgRQF8nii6GWfoyK3l5WXNzc3pgQceULVa1dDQkB5++GHdf//9WY8GJMIZOnJraGhIg4ODOnfunE6dOqVz585pcHBQQ0NDWY8GJELQkVvT09OanJzU6dOntbq6qtOnT2tyclLT09NZjwYkwpILcmtiYkKSNi25zMzMXN4OdBteKQpIqlQqGhkZyXoM4Kp4pSgA5AxBB4AgCDoABEHQASAIgg4AQWzrVS5m9pak17btgMCNu0XSz7IeAriGT7n7x5vttK1BBzqVmS3eyGVhQCdjyQUAgiDoABAEQQcuOZH1AEBarKEDQBCcoQNAEAQduWdmf2hm3zezH5jZsaznAZJiyQW5ZmY9kv5H0rikmqTvSZpw91cyHQxIgDN05N1+ST9w9x+6+/uS/lnSXRnPBCRC0JF3eyT9+IrvaxvbgK5D0JF3dpVtrEOiKxF05F1N0iev+H5Q0nJGswCpEHTk3fck/baZ7TOzj0i6R9K3M54JSIQPiUauufuqmf2ppO9K6pF00t1fzngsIBEuWwSAIFhyAYAgCDoABEHQASAIgg4AQRB0AAiCoANAEAQdAIIg6AAQxK8AQT1gPpxh684AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "#cal the predicted value\n",
    "y_pred = (scaled_test_x).dot(w)\n",
    "print(\"ypred is\" ,y_pred)\n",
    "#Calculating MSE\n",
    "MSE = mean_squared_error(y_test,y_pred)\n",
    "print(\"MSE is \" , MSE)\n",
    "#Calculating RMSE\n",
    "RMSE = math.sqrt(MSE)\n",
    "print(\"RMSE is \", RMSE )\n",
    "y_pred.boxplot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat TASK 10 additional four times : Run linear regression training again\n",
    "### After each run, Report RMSE(testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE1 is  1.171556637051285\n",
      "RMSE1 is  1.0823846991949235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#Run1 .. Running the whole process from splitting the data 80-20 , scalling and calculating w then MSE then RMSE \n",
    "from sklearn.model_selection import train_test_split\n",
    "df_split1 = train\n",
    "test1 , train1 =train_test_split(df_split1,test_size=0.8) \n",
    "x1=train1[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y1=train1[['BWEIGHT']]\n",
    "x1_test=test1[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y1_test=test1[['BWEIGHT']]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler2 = StandardScaler()\n",
    "scaled_train1_x = pd.DataFrame(scaler.fit_transform(x1) , columns=x1.columns )\n",
    "scaled_train1_x.head()\n",
    "\n",
    "scaled_train1_x['x0'] =1\n",
    "scaled_train1_x.head()\n",
    "scaler3 = StandardScaler()\n",
    "scaled_test1_x = pd.DataFrame(scaler3.fit_transform(x1_test), columns=x1_test.columns)\n",
    "scaled_test1_x['x0'] =1\n",
    "scaled_test1_x.head()\n",
    "\n",
    "M1 = scaled_train1_x.T.dot(scaled_train1_x)\n",
    "M1inv = np.linalg.pinv(M1)\n",
    "w1 =M1inv.dot(scaled_train1_x.T).dot(y1)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "y1_pred = (scaled_test1_x).dot(w1)\n",
    "MSE1 = mean_squared_error(y1_test,y1_pred)\n",
    "print(\"MSE1 is \" , MSE1)\n",
    "RMSE1 = math.sqrt(MSE1)\n",
    "print(\"RMSE1 is \", RMSE1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE2 is  1.154644144773977\n",
      "RMSE2 is  1.0745436914216084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#Run2 .. Running the whole process from splitting the data 80-20 , scalling and calculating w then MSE then RMSE \n",
    "from sklearn.model_selection import train_test_split\n",
    "df_split2 = train1\n",
    "test2 , train2 =train_test_split(df_split2,test_size=0.8) \n",
    "x2=train2[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y2=train2[['BWEIGHT']]\n",
    "x2_test=test2[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y2_test=test2[['BWEIGHT']]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler4 = StandardScaler()\n",
    "scaled_train2_x = pd.DataFrame(scaler4.fit_transform(x2) , columns=x2.columns )\n",
    "scaled_train2_x.head()\n",
    "\n",
    "scaled_train2_x['x0'] =1\n",
    "scaled_train2_x.head()\n",
    "scaler5 = StandardScaler()\n",
    "scaled_test2_x = pd.DataFrame(scaler5.fit_transform(x2_test), columns=x2_test.columns)\n",
    "scaled_test2_x['x0'] =1\n",
    "scaled_test2_x.head()\n",
    "\n",
    "M2 = scaled_train2_x.T.dot(scaled_train2_x)\n",
    "M2inv = np.linalg.pinv(M2)\n",
    "w2 =M2inv.dot(scaled_train2_x.T).dot(y2)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "y2_pred = (scaled_test2_x).dot(w2)\n",
    "MSE2 = mean_squared_error(y2_test,y2_pred)\n",
    "print(\"MSE2 is \" , MSE2)\n",
    "RMSE2 = math.sqrt(MSE2)\n",
    "print(\"RMSE2 is \", RMSE2 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE3 is  1.1483171309287088\n",
      "RMSE3 is  1.071595600461624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#Run3 .. Running the whole process from splitting the data 80-20 , scalling and calculating w then MSE then RMSE \n",
    "from sklearn.model_selection import train_test_split\n",
    "df_split3 = train2\n",
    "test3 , train3 =train_test_split(df_split3,test_size=0.8) \n",
    "x3=train3[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y3=train3[['BWEIGHT']]\n",
    "x3_test=test3[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y3_test=test3[['BWEIGHT']]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler6 = StandardScaler()\n",
    "scaled_train3_x = pd.DataFrame(scaler6.fit_transform(x3) , columns=x3.columns )\n",
    "scaled_train3_x.head()\n",
    "\n",
    "scaled_train3_x['x0'] =1\n",
    "scaled_train3_x.head()\n",
    "scaler7 = StandardScaler()\n",
    "scaled_test3_x = pd.DataFrame(scaler7.fit_transform(x3_test), columns=x3_test.columns)\n",
    "scaled_test3_x['x0'] =1\n",
    "scaled_test3_x.head()\n",
    "\n",
    "M3 = scaled_train3_x.T.dot(scaled_train3_x)\n",
    "M3inv = np.linalg.pinv(M3)\n",
    "w3 =M3inv.dot(scaled_train3_x.T).dot(y3)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "y3_pred = (scaled_test3_x).dot(w3)\n",
    "MSE3 = mean_squared_error(y3_test,y3_pred)\n",
    "print(\"MSE3 is \" , MSE3)\n",
    "RMSE3 = math.sqrt(MSE3)\n",
    "print(\"RMSE3 is \", RMSE3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE4 is  1.162879393470901\n",
      "RMSE4 is  1.078368857799084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#Run4 .. Running the whole process from splitting the data 80-20 , scalling and calculating w then MSE then RMSE \n",
    "from sklearn.model_selection import train_test_split\n",
    "df_split4 = train3\n",
    "test4 , train4 =train_test_split(df_split4,test_size=0.8) \n",
    "x4=train4[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y4=train4[['BWEIGHT']]\n",
    "x4_test=test4[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y4_test=test4[['BWEIGHT']]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler8 = StandardScaler()\n",
    "scaled_train4_x = pd.DataFrame(scaler8.fit_transform(x4) , columns=x4.columns )\n",
    "scaled_train4_x.head()\n",
    "\n",
    "scaled_train4_x['x0'] =1\n",
    "scaled_train4_x.head()\n",
    "scaler9 = StandardScaler()\n",
    "scaled_test4_x = pd.DataFrame(scaler9.fit_transform(x4_test), columns=x4_test.columns)\n",
    "scaled_test4_x['x0'] =1\n",
    "scaled_test4_x.head()\n",
    "\n",
    "M4 = scaled_train4_x.T.dot(scaled_train4_x)\n",
    "M4inv = np.linalg.pinv(M4)\n",
    "w4 =M4inv.dot(scaled_train4_x.T).dot(y4)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "y4_pred = (scaled_test4_x).dot(w4)\n",
    "MSE4 = mean_squared_error(y4_test,y4_pred)\n",
    "print(\"MSE4 is \" , MSE4)\n",
    "RMSE4 = math.sqrt(MSE4)\n",
    "print(\"RMSE4 is \", RMSE4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12: Finally, Report RMSE(testing) = Average(RMSE_test) $\\pm$ Stdev(RMSE_test)\n",
    "### Here Average(RMSE_test) = average of all the 5 RMSE(testing) scores you got above.\n",
    "### And, stdev(RMSE_test) = standard deviation of all the 5 RMSE(testing) scores above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE 1.0763023757837957\n",
      "Standard Deviation is  0.0037241203928866334\n",
      "RMSE final is 1.0737690442555394\n"
     ]
    }
   ],
   "source": [
    "#cal RMSE avg\n",
    "R1 = RMSE,RMSE1,RMSE2,RMSE3,RMSE4\n",
    "RMSE_Ave = np.average(R1)\n",
    "#cal RMSE stdev\n",
    "RMSE_Stdev = np.std(R1)\n",
    "print(\"Average RMSE\" ,RMSE_Ave)\n",
    "print(\"Standard Deviation is \" ,RMSE_Stdev)\n",
    "#RMSE_Final = RMSE_Ave +- RMSE_Stdev\n",
    "#RMSE FInal cal\n",
    "RMSE_FINAL = abs(RMSE_Ave) - abs(RMSE-Stdev)\n",
    "print(\"RMSE final is\" , RMSE_Final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 13: Run linear regression one last time on the whole dataset  (i.e, training+testing which is preprocessed by you above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE5 is  1.1566603244806195\n",
      "RMSE5 is  1.071595600461624\n"
     ]
    }
   ],
   "source": [
    "#performing the whole process again on the data and finding RMSE\n",
    "x5=df_dataset[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y5=df_dataset[['BWEIGHT']]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler10 = StandardScaler()\n",
    "scaled_data_x = pd.DataFrame(scaler10.fit_transform(x5) , columns=x5.columns )\n",
    "\n",
    "\n",
    "scaled_data_x['x0'] =1\n",
    "\n",
    "M5 = scaled_data_x.T.dot(scaled_data_x)\n",
    "M5inv = np.linalg.pinv(M5)\n",
    "w5 =M3inv.dot(scaled_train3_x.T).dot(y3)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "y5_pred = (scaled_data_x).dot(w5)\n",
    "MSE5 = mean_squared_error(y5,y5_pred)\n",
    "print(\"MSE5 is \" , MSE5)\n",
    "RMSE5 = math.sqrt(MSE3)\n",
    "print(\"RMSE5 is \", RMSE5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 14: Preprocess the judge-without-label.csv file according টo the strategy you applied above on the whole dataset (task 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2001, 36)\n",
      "['ID', 'SEX', 'MARITAL', 'FAGE', 'GAINED', 'VISITS', 'MAGE', 'FEDUC', 'MEDUC', 'TOTALP', 'BDEAD', 'TERMS', 'LOUTCOME', 'WEEKS', 'RACEMOM', 'RACEDAD', 'CIGNUM', 'DRINKNUM', 'ANEMIA', 'CARDIAC', 'ACLUNG', 'DIABETES', 'HERPES', 'HYDRAM', 'HEMOGLOB', 'HYPERCH', 'HYPERPR', 'ECLAMP', 'CERVIX', 'PINFANT', 'PRETERM', 'RENAL', 'RHSEN', 'UTERINE', 'HISPMOM_M', 'HISPMOM_N', 'HISPMOM_O', 'HISPMOM_P', 'HISPMOM_S', 'HISPDAD_C', 'HISPDAD_M', 'HISPDAD_N', 'HISPDAD_O', 'HISPDAD_P', 'HISPDAD_S', 'HISPDAD_U']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#Load Judge witout labels \n",
    "df_judge = pd.read_csv('C:/Users/kusha/Desktop/sem2/ML/programming assignment/new/judge-without-labels.csv')\n",
    "print(df_judge.shape)\n",
    "#Creating dummy variables\n",
    "df_df=pd.get_dummies(df_judge)\n",
    "print(list(df_df.columns))\n",
    "#Selecting variables\n",
    "df_Newjudge = df_df[['WEEKS','GAINED','VISITS','MAGE']]\n",
    "#Normalisinig \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_a = StandardScaler()\n",
    "scaled_judge_x = pd.DataFrame(scaler_a.fit_transform(df_Newjudge) , columns=df_Newjudge.columns )\n",
    "#Adding Bias\n",
    "scaled_judge_x['x0'] =1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 15: Predict BWEIGHT for each of the samples from the judge-without-label.csv file, and save the results in judge-submission-run-1.csv in the format below. Please change the run number and report what changes you have made in a corresponding file run-1.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID   BWEIGHT\n",
      "0        0  6.861970\n",
      "1        1  7.771261\n",
      "2        2  7.086132\n",
      "3        3  7.101974\n",
      "4        4  7.100973\n",
      "5        5  7.432190\n",
      "6        6  6.606312\n",
      "7        7  7.020134\n",
      "8        8  8.073950\n",
      "9        9  6.794155\n",
      "10      10  7.924461\n",
      "11      11  7.310363\n",
      "12      12  7.609299\n",
      "13      13  7.175766\n",
      "14      14  5.240404\n",
      "15      15  6.754299\n",
      "16      16  7.396077\n",
      "17      17  7.288279\n",
      "18      18  6.262598\n",
      "19      19  7.723824\n",
      "20      20  7.472983\n",
      "21      21  7.366459\n",
      "22      22  7.770556\n",
      "23      23  7.534723\n",
      "24      24  7.034483\n",
      "25      25  8.057737\n",
      "26      26  6.904589\n",
      "27      27  7.170489\n",
      "28      28  7.398936\n",
      "29      29  7.633402\n",
      "...    ...       ...\n",
      "1971  1971  7.094092\n",
      "1972  1972  7.179941\n",
      "1973  1973  7.463479\n",
      "1974  1974  7.638809\n",
      "1975  1975  6.333215\n",
      "1976  1976  6.938821\n",
      "1977  1977  8.306901\n",
      "1978  1978  6.185548\n",
      "1979  1979  7.442531\n",
      "1980  1980  7.202168\n",
      "1981  1981  7.449051\n",
      "1982  1982  7.420222\n",
      "1983  1983  7.347277\n",
      "1984  1984  7.185835\n",
      "1985  1985  6.552929\n",
      "1986  1986  7.631127\n",
      "1987  1987  7.969725\n",
      "1988  1988  7.468613\n",
      "1989  1989  8.321292\n",
      "1990  1990  7.019216\n",
      "1991  1991  7.870787\n",
      "1992  1992  8.241090\n",
      "1993  1993  4.954540\n",
      "1994  1994  7.870023\n",
      "1995  1995  5.810541\n",
      "1996  1996  7.132332\n",
      "1997  1997  7.569743\n",
      "1998  1998  7.136780\n",
      "1999  1999  5.726420\n",
      "2000  2000  5.759827\n",
      "\n",
      "[2001 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Predicting the BWEIGHT\n",
    "y_judge= (scaled_judge_x).dot(w)\n",
    "y_jud =pd.DataFrame(y_judge)\n",
    "\n",
    "y_jud.columns =['BWEIGHT']\n",
    "#print(y_judge)\n",
    "df_id = df_df[['ID']]\n",
    "df_id['BWEIGHT']= y_jud.BWEIGHT.values\n",
    "\n",
    "\n",
    "header =['ID', 'BWEIGHT']\n",
    "print(df_id)\n",
    "#Copying it to the CSV file\n",
    "df_id.to_csv(\"judge-submission-run-5.csv\" , columns = header , index = False)\n",
    "#np.savetxt(\"judge-submission-run-2.csv\", y_judge)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks only for CSCI-5930 (Grad) students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 16: Repeat tasks 9-12 three times, and report the ultimate RMSE_test average $\\pm$ ultimate RMSE_test stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE11 is  1.1496738502853727\n",
      "RMSE11 is  1.072228450604335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#Run1 .. Running the whole process from splitting the data 80-20 , scalling and calculating w then MSE then RMSE \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_split11 = train4\n",
    "test11 , train11 =train_test_split(df_split11,test_size=0.8) \n",
    "x11=train11[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y11=train11[['BWEIGHT']]\n",
    "x11_test=test11[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y11_test=test11[['BWEIGHT']]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler11 = StandardScaler()\n",
    "scaled_train11_x = pd.DataFrame(scaler11.fit_transform(x11) , columns=x11.columns )\n",
    "scaled_train11_x.head()\n",
    "\n",
    "scaled_train11_x['x0'] =1\n",
    "scaled_train11_x.head()\n",
    "scaler12 = StandardScaler()\n",
    "scaled_test11_x = pd.DataFrame(scaler12.fit_transform(x11_test), columns=x11_test.columns)\n",
    "scaled_test11_x['x0'] =1\n",
    "scaled_test11_x.head()\n",
    "\n",
    "M11 = scaled_train11_x.T.dot(scaled_train11_x)\n",
    "M11inv = np.linalg.pinv(M11)\n",
    "w11 =M11inv.dot(scaled_train11_x.T).dot(y11)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "y11_pred = (scaled_test11_x).dot(w11)\n",
    "MSE11 = mean_squared_error(y11_test,y11_pred)\n",
    "print(\"MSE11 is \" , MSE11)\n",
    "RMSE11 = math.sqrt(MSE11)\n",
    "print(\"RMSE11 is \", RMSE11)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE12 is  1.1564363014388073\n",
      "RMSE12 is  1.0753772833005202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "##Run2 .. Running the whole process from splitting the data 80-20 , scalling and calculating w then MSE then RMSE \n",
    "from sklearn.model_selection import train_test_split\n",
    "df_split12 = train11\n",
    "test12 , train12 =train_test_split(df_split12,test_size=0.8) \n",
    "x12=train12[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y12=train12[['BWEIGHT']]\n",
    "x12_test=test12[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y12_test=test12[['BWEIGHT']]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler13 = StandardScaler()\n",
    "scaled_train12_x = pd.DataFrame(scaler13.fit_transform(x12) , columns=x12.columns )\n",
    "scaled_train12_x.head()\n",
    "\n",
    "scaled_train12_x['x0'] =1\n",
    "scaled_train12_x.head()\n",
    "scaler14 = StandardScaler()\n",
    "scaled_test12_x = pd.DataFrame(scaler14.fit_transform(x12_test), columns=x12_test.columns)\n",
    "scaled_test12_x['x0'] =1\n",
    "scaled_test12_x.head()\n",
    "\n",
    "M12 = scaled_train12_x.T.dot(scaled_train12_x)\n",
    "M12inv = np.linalg.pinv(M12)\n",
    "w12 =M12inv.dot(scaled_train12_x.T).dot(y12)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "y12_pred = (scaled_test12_x).dot(w12)\n",
    "MSE12 = mean_squared_error(y12_test,y12_pred)\n",
    "print(\"MSE12 is \" , MSE12)\n",
    "RMSE12 = math.sqrt(MSE12)\n",
    "print(\"RMSE12 is \", RMSE12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE13 is  1.07975646219675\n",
      "RMSE13 is  1.0391133057548392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kusha\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#RUN3 .. Running the whole process from splitting the data 80-20 , scalling and calculating w then MSE then RMSE \n",
    "from sklearn.model_selection import train_test_split\n",
    "df_split13 = train12\n",
    "test13 , train13 =train_test_split(df_split13,test_size=0.8) \n",
    "x13=train13[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y13=train13[['BWEIGHT']]\n",
    "x13_test=test13[['WEEKS', 'GAINED','VISITS','MAGE']]\n",
    "y13_test=test13[['BWEIGHT']]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler15 = StandardScaler()\n",
    "scaled_train13_x = pd.DataFrame(scaler15.fit_transform(x13) , columns=x13.columns )\n",
    "scaled_train13_x.head()\n",
    "\n",
    "scaled_train13_x['x0'] =1\n",
    "scaled_train13_x.head()\n",
    "scaler16 = StandardScaler()\n",
    "scaled_test13_x = pd.DataFrame(scaler14.fit_transform(x13_test), columns=x13_test.columns)\n",
    "scaled_test13_x['x0'] =1\n",
    "scaled_test13_x.head()\n",
    "\n",
    "M13 = scaled_train13_x.T.dot(scaled_train13_x)\n",
    "M13inv = np.linalg.pinv(M13)\n",
    "w13 =M13inv.dot(scaled_train13_x.T).dot(y13)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "y13_pred = (scaled_test13_x).dot(w13)\n",
    "MSE13 = mean_squared_error(y13_test,y13_pred)\n",
    "print(\"MSE13 is \" , MSE13)\n",
    "RMSE13 = math.sqrt(MSE13)\n",
    "print(\"RMSE13 is \", RMSE13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ultimate RMSE 1.0710288648223343\n",
      "Standard Ultimate Deviation is  0.012486721010274367\n",
      "RMSE ultimate is 1.05854214381206\n"
     ]
    }
   ],
   "source": [
    "#Finding the ultimate RMSE\n",
    "R2 = RMSE,RMSE1,RMSE2,RMSE3,RMSE4,RMSE11,RMSE12,RMSE13\n",
    "#Average RMSE\n",
    "RMSE_Ultimate_Ave = np.average(R2)\n",
    "#RMSE standard deviation\n",
    "RMSE_Ultimate_Stdev = np.std(R2)\n",
    "print(\"Average Ultimate RMSE\" ,RMSE_Ultimate_Ave)\n",
    "print(\"Standard Ultimate Deviation is \" ,RMSE_Ultimate_Stdev)\n",
    "#Calculating ultimate absolute value of RMSE\n",
    "RMSE_Ultimate = abs(RMSE_Ultimate_Ave) - abs(RMSE_Ultimate_Stdev)\n",
    "print(\"RMSE ultimate is\" , RMSE_Ultimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 17: Make an entry in the Kaggle challenge [https://www.kaggle.com/c/csci-ml-s19-pa1/] by joining and submitting the judge-submission-run1.csv file, and please report your Kaggle handle here too.\n",
    "### There is limit of 5 entries each day untile the deadline.\n",
    "### For each of the runs you submit, please report here the RMSE you got (as reported by the Kaggle platform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#kushal ganti \n",
    "#score was 1.08918\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16.0,
    "lenType": 16.0,
    "lenVar": 40.0
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
